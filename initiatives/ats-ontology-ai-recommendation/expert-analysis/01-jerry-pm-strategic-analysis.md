# 제리(Jerry) - B2B SaaS PM 전략 분석

**전문가**: 제리 (B2B SaaS 제품 전략 전문가)
**분석일**: 2025-12-03
**관점**: Product Management, Go-to-Market Strategy, Business Viability

---

## 요약 (Executive Summary)

온톨로지 기반 AI 추천 시스템은 **기술적으로는 흥미롭지만, 비즈니스 관점에서는 상당한 검증이 필요**합니다. 가장 큰 리스크는 "기술에 빠져 고객을 잃는 것"입니다.

**핵심 제안**:
- Wave 1 (MVP)은 **프로세스 병목 진단**으로 시작 (낮은 리스크, 명확한 ROI)
- 온톨로지 전체 구축 전에 **1개 Use Case로 비즈니스 가치 증명**
- 3-Phase 점진적 접근으로 **기술 리스크와 시장 리스크 분리**

---

## 1. 제품 관점 타당성 평가

### ✅ 강점 (Strengths)

#### 차별화된 데이터 자산
- 동적 프로세스 데이터는 기존 ATS가 거의 활용하지 못하는 영역
- 정적 JD 매칭의 한계(낮은 적중률, 맥락 부족)는 실제 고객 Pain Point
- **방어 가능성**: 온톨로지는 데이터가 쌓일수록 네트워크 효과 창출

#### 시장 타이밍
- LLM/RAG 기술 성숙도와 기업의 AI 도입 의지가 만나는 시점
- B2B SaaS 시장에서 AI는 더 이상 "Nice-to-have"가 아닌 "Must-have"

#### 높은 잠재 가치
1. **리스크 회피**: 잘못된 채용의 비용 = 연봉의 1.5~3배 → 위험 시그널 조기 감지는 직접적 ROI
2. **속도**: 채용 리드타임 단축 = 기회비용 감소 (특히 기술직, 임원급)
3. **일관성**: 평가 편향 감소, 구조화된 의사결정 → Compliance, 브랜드 가치

### ⚠️ 주의사항 (Concerns)

#### 복잡도의 함정
- "온톨로지 + 지식그래프 + LLM"은 B2B 구매자에게 **블랙박스**
- 가치 제안이 기술 스펙이 아닌 **비즈니스 결과**로 표현되어야 함
- 예시:
  - ❌ "지식그래프 기반 AI 추천"
  - ✅ "채용 실패 확률 50% 감소"

#### 시장 교육 비용
- 현재 ATS 시장은 "더 나은 매칭"보다 **"워크플로우 효율화"**에 초점
- 새로운 가치 축을 만드는 것 = 긴 판매 주기 (B2B SaaS에서 12-18개월 일반적)
- Early Adopter 확보 후 Chasm 넘기가 관건

#### 경쟁 환경
- Greenhouse, Lever 같은 선두주자들이 AI 기능을 추가하는 속도가 빠름
- 차별화 지속 가능성을 **계속** 검증해야 함 (일회성 검증으로 끝나지 않음)

### 🔍 검증 필요 영역

#### 지불 의지 (Willingness to Pay)
- 고객이 "더 정확한 매칭"에 얼마를 지불할까?
- 기존 비용 구조(per-seat $50-150, per-hire $500-2000)와 어떻게 정렬?
- **테스트 방법**: Van Westendorp Price Sensitivity Meter

#### 채택 장벽 (Adoption Barriers)
- 실제 사용자(리크루터, 채용 매니저)가 AI 추천을 신뢰하고 **행동을 바꿀까?**
- HireVue 사례: AI 면접 평가 도입했다가 엄청난 반발 → 참고용으로만 사용
- **테스트 방법**: Wizard of Oz 테스트 (수동 인사이트 제공 → 행동 변화 관찰)

---

## 2. 검증해야 할 핵심 가정 5가지

### 가정 1: 가치 가정 ⚠️ **최고 리스크**
**진술**: 채용 담당자는 프로액티브한 AI 인사이트를 충분히 가치있게 여겨 행동을 바꿀 것이다.

**왜 위험한가?**
- AI 추천을 "참고"만 하고 무시하면 제품 가치 = 0
- LinkedIn Recruiter의 "Recommended matches"도 첫 화면용일 뿐, 최종 결정은 사람

**테스트 방법**:
```
Wizard of Oz Test (8주 프로그램)
1. 3-5개 고객 선정
2. 수동으로 인사이트 생성 (AI인 척)
   - "후보 A는 과거 3번 레퍼런스 체크에서 중단됨"
   - "이 프로세스는 평균보다 2배 느림, 병목: CTO 승인"
   - "유사 후보 5명 중 4명이 오퍼레터, 예상 사유: 연봉"
3. 주간 리포트 이메일 발송
4. 행동 추적: 리포트 열람 → 실제 액션 (재평가, 리마인더 발송 등)
```

**성공 기준**:
- 30일 내 60% 이상이 인사이트 기반 액션 1회 이상 실행
- 8주 후 NPS 40 이상

**학습 목표**:
- 어떤 인사이트가 행동을 유발하는가?
- 신뢰 장벽은 무엇인가? (설명 부족? 정확도 의심?)

---

### 가정 2: 사용성 가정 ⚠️ **높은 리스크**
**진술**: 리크루터가 현재 워크플로우를 크게 바꾸지 않고도 AI 기능을 일상에 통합할 수 있다.

**왜 위험한가?**
- B2B SaaS의 최대 실패 원인: "좋은 기능인데 아무도 안 써요"
- 새로운 툴 학습 부담 > 얻는 가치 → 이탈

**테스트 방법**:
```
프로토타입 관찰 (5명 리크루터)
1. Figma/Wizard of Oz 프로토타입 제작
2. 실제 작업 중 사용 관찰 (30-60분)
3. Think-aloud 프로토콜
4. 교육 없이 핵심 기능 3회 사용 가능한지 측정
```

**성공 기준**:
- 70% 이상이 교육 없이 핵심 기능 3회 사용
- 평균 3분 이내 첫 가치 발견 (Aha Moment)

**학습 목표**:
- 정보 과부하 vs 부족
- 신뢰 메커니즘 (설명 가능성)
- 통합 지점 (Greenhouse UI 내부? 별도 대시보드?)

---

### 가정 3: 기술적 실현 가능성 ⚠️ **높은 리스크**
**진술**: 현재 데이터 품질과 구조로 의미있는 정확도의 온톨로지를 6개월 내 구축할 수 있다.

**왜 위험한가?**
- 온톨로지는 "Garbage In, Garbage Out"
- 면접 평가가 "Good", "Pass" 같은 한 단어만 있으면 의미있는 관계 추출 불가능

**테스트 방법**:
```
Phase 1: 데이터 품질 감사 (Week 3)
- 무작위 100개 채용 프로세스 샘플
- 필드 완성도, 일관성, 노이즈 레벨 측정
- 온톨로지 핵심 엔티티 추출 가능성 검증

Phase 2: PoC Spike (Week 7-8, 2주 타임박스)
- 1개 고객 데이터로 미니 온톨로지 구축
- Use Case 1 (병목 진단) 구현
- 정확도 기준선 측정 (수동 레이블링 vs AI 출력)
```

**성공 기준**:
- 데이터 품질 70% 이상 (필수 필드 완성도)
- PoC에서 1개 Use Case 70% 정확도

**학습 목표**:
- 온톨로지가 실제로 필요한가? (vs 단순 휴리스틱)
- LLM이 어디에 필요한가? (추론 vs 분류)
- 데이터 정제에 얼마나 투자해야 하나?

---

### 가정 4: 경제성 가정 (중간 리스크)
**진술**: 고객이 이 기능에 대해 기존 ATS 비용의 30-50% 프리미엄을 지불할 의향이 있다.

**테스트 방법**:
```
가치 기반 가격 인터뷰 (10-15개 고객)
1. Van Westendorp 4가지 질문:
   - "너무 싸서 품질이 의심되는 가격은?"
   - "저렴하다고 느끼는 가격은?"
   - "비싸지만 가치있다면 낼 수 있는 가격은?"
   - "너무 비싸서 절대 못 내는 가격은?"
2. Conjoint Analysis 간소화 버전:
   - 기능별 상대적 가치 평가
   - "병목 진단 vs 위험 시그널 vs 후보자 추천 중 우선순위는?"
```

**성공 기준**:
- 40% 이상이 "비싸지만 살 것" 범위에서 목표 가격 수용
- Acceptable Price Range = $X-Y/user/month

---

### 가정 5: 차별화 지속성 (중간 리스크)
**진술**: 온톨로지 접근은 네트워크 효과를 만들어 12-18개월 경쟁 우위를 유지할 수 있다.

**테스트 방법**:
```
1. 경쟁사 기술 스택 분석
   - Greenhouse, Lever, Workday AI 기능 상세 리뷰
   - 최근 3개월 product update 추적
   - 기술 블로그, 채용 공고에서 AI 전략 추론

2. 기술 벤치마킹
   - 온톨로지 vs 단순 RAG 정확도 비교 (동일 데이터셋)
   - 어떤 Use Case에서 온톨로지가 필수인가?
```

**성공 기준**:
- 온톨로지가 핵심 메트릭(정확도, 추론 깊이)에서 20% 이상 우수
- 경쟁사 유사 기능 출시까지 12개월 이상 예상

---

## 3. MVP 범위 제안

### MVP 철학: "가장 작은 가치 증명"
온톨로지 전체를 구축하기 전에, **1개 Use Case로 비즈니스 가치와 기술 실현가능성을 동시에 검증**합니다.

### 🎯 추천 MVP Use Case: **"채용 프로세스 병목 진단 & 액션 추천"**

#### 선정 이유 (4가지 기준)

| 기준 | 평가 | 근거 |
|------|------|------|
| 가치 명확성 | ⭐⭐⭐⭐⭐ | 리드타임 단축 = 직접적 ROI (시간 = 돈) |
| 데이터 접근성 | ⭐⭐⭐⭐⭐ | 이미 보유 (단계별 타임스탬프, 상태 전환) |
| 복잡도 제어 | ⭐⭐⭐⭐ | 후보자 매칭보다 프로세스 분석이 온톨로지 설계 단순 |
| 차별화 | ⭐⭐⭐⭐ | 기존 ATS는 "평균 리드타임" 같은 정적 지표만 제공 |

#### MVP 기능 범위

**Core 기능 (3개):**

**1. 프로세스 이상 감지**
```
온톨로지 엔티티:
- Recruitment_Process (id, job_posting_id, status, created_at)
- Stage_Transition (from_stage, to_stage, duration, timestamp)
- Historical_Benchmark (avg_duration_by_role, avg_duration_by_team)

출력 예시:
"이 프로세스는 평균보다 2배 느립니다.
병목: 2차 면접 → 최종 결정 (15일 vs 평균 7일)"
```

**2. 맥락 기반 원인 추론**
```
온톨로지 관계:
- Process ↔ Evaluator (누가 지연시키는가?)
- Process ↔ Role (어떤 역할이 느린가?)
- Process ↔ Org_Structure (승인 단계가 많은가?)

출력 예시:
"가능한 원인:
(1) 최종 결정자 김OO 님이 최근 3건에서 평균 10일 응답
(2) 이 역할은 3개 부서 승인 필요 (vs 평균 1.5개)
(3) 연말 시즌으로 전체 프로세스가 20% 지연 중"
```

**3. 액션 추천**
```
출력 예시:
"제안:
(1) 김OO 님에게 리마인더 발송 (템플릿 제공)
(2) 병렬 승인 프로세스 고려 (A부서, B부서 동시 진행)
(3) 유사 역할 평균 리드타임 7일 - 이번 주 내 결정 목표"
```

#### Non-goals (명시적 제외)
- ❌ 후보자 추천/매칭 (Wave 2)
- ❌ 평가 내용 분석 (텍스트 마이닝 복잡도 높음)
- ❌ 외부 데이터 통합 (LinkedIn, GitHub - Wave 3)
- ❌ 실시간 알림 (배치 주간 리포트로 시작)

#### MVP 성공 기준

| 메트릭 | 목표 | 측정 방법 |
|--------|------|----------|
| 정확도 | 70% | 병목 진단을 리크루터가 검증 (맞음/틀림) |
| 채택률 | 60% | 파일럿 5개 중 3개가 8주간 주간 리포트 지속 확인 |
| 비즈니스 임팩트 | 15% | 1개 이상 고객에서 평균 리드타임 감소 (before/after) |
| 기술 학습 | - | 온톨로지 스키마 안정화, LLM 프롬프트 패턴 확립 |

---

## 4. 우선순위 기준 및 로드맵

### 우선순위 프레임워크: RICE + Risk

| Use Case | Reach | Impact | Confidence | Effort | Risk | RICE | 순위 |
|----------|-------|--------|------------|--------|------|------|------|
| 프로세스 병목 진단 | 80% | High (3) | 70% | 3개월 | Medium | 56 | 🥇 1 |
| 역량 기반 매칭 | 70% | High (3) | 50% | 5개월 | High | 21 | 🥈 2 |
| 후보자 위험 시그널 | 60% | High (3) | 40% | 4개월 | High | 18 | 🥉 3 |
| 프로액티브 추천 | 50% | Critical (4) | 30% | 6개월 | High | 10 | 4 |
| 평가 일관성 분석 | 40% | Medium (2) | 50% | 3개월 | Medium | 13 | 5 |

**우선순위 결정 논리:**

**Wave 1 (MVP, 0-6개월): 프로세스 병목 진단**
- 낮은 리스크, 명확한 가치, 온톨로지 기초 확립
- 조건: 성공 기준 70% 이상 달성

**Wave 2 (확장, 6-12개월): 역량 기반 매칭**
- 후보자 엔티티 추가, 시장 차별화 강화
- 조건: Wave 1 성공 + 10개 이상 고객 데이터 축적

**Wave 3 (혁신, 12-18개월): 위험 시그널 + 프로액티브 추천**
- 고도화된 관계 추론, LLM 고도화
- 조건: Wave 2 성공 + 온톨로지 v3.0 안정화

### 로드맵 마일스톤

```
Q1 (Week 1-12): Discovery + MVP
├─ Week 1-4: 가정 테스트 (고객 인터뷰 10명, 데이터 감사)
├─ Week 5-8: MVP 병목 진단 PoC
└─ Week 9-12: 5개 고객 파일럿, 피드백 루프
    Exit Criteria: 성공 기준 3/4 달성 → Wave 2 진행

Q2 (Week 13-24): Scale Wave 1 + Wave 2 시작
├─ Week 13-16: 병목 진단 GA (General Availability)
├─ Week 17-20: 역량 기반 매칭 PoC
└─ Week 21-24: 온톨로지 스키마 v2.0 (후보자 엔티티)
    Exit Criteria: ARR $X 달성 → Wave 3 투자

Q3-Q4: Wave 2 Scale + Wave 3 시작
```

---

## 5. PM이 집중해야 할 핵심 활동

### Phase 1: Discovery & Validation (Week 1-8)

#### 🎯 활동 1: 고객 발견 인터뷰
**목표**: 가정 1, 2, 4 검증

**대상 (10-15명)**:
- 현재 고객 5명 (다양한 규모)
- 잠재 고객 5명 (경쟁사 ATS 사용 중)
- Churned 고객 2-3명 (왜 떠났는지)

**구조화된 질문 (JTBD 프레임워크)**:
1. **Jobs to be Done**
   - "최근 채용 실패/지연 사례 3개는?"
   - "무엇이 잘못되었나? 어떤 시그널을 놓쳤나?"
   - "이상적인 채용 프로세스 vs 현실 차이는?"

2. **현재 데이터 활용 실태**
   - "현재 데이터를 어떻게 활용하나?"
   - "어떤 인사이트를 원하나?"
   - "과거 채용 데이터를 다시 찾아본 적 있나? 언제?"

3. **Wizard of Oz 시연**
   - 시나리오 1: "후보 A는 과거 3번 레퍼런스 체크에서 중단"
   - 시나리오 2: "프로세스 2배 느림, 병목: CTO 면접"
   - 시나리오 3: "유사 후보 5명 중 4명 오퍼레터, 사유: 연봉"
   - "이런 알림 받으면 어떻게 행동하겠나?"

**도구**: `/frameworks/continuous-discovery-habits/create-interview-snapshots.mdc`

**산출물**:
- 10개 Interview Snapshots
- Pain Point 우선순위 맵
- Wizard of Oz 테스트 결과 (행동 전환율)

---

#### 🎯 활동 2: 데이터 품질 감사
**목표**: 가정 3 검증

**방법**:
1. 5개 대표 고객 데이터 샘플 추출 (각 50-100 프로세스)
2. 필드 완성도 스코어카드 작성
3. 온톨로지 핵심 엔티티 추출 가능성 평가

**스코어카드 예시**:
```
필수 필드 (MVP 온톨로지):
- 후보자 정보: 95%+ 필요
- 단계 전환 타임스탬프: 90%+ 필요
- 면접 평가 점수: 70%+ 필요
- 평가 코멘트 (텍스트): 50%+ 희망
- 오퍼레터 사유: 60%+ 필요
```

**산출물**:
- 데이터 품질 리포트
- 온톨로지 스키마 v0.1
- "Go/No-Go/Conditional" 판단

---

#### 🎯 활동 3: 경쟁 분석 및 포지셔닝
**목표**: 가정 5 검증

**분석 대상**:
- Greenhouse, Lever AI 기능 상세 리뷰 (기능, 가격, 고객 리뷰)
- 최근 3개월 product update 추적
- 기술 블로그, 채용 공고에서 AI 전략 추론

**산출물**:
- 경쟁 매트릭스 (기능, 가격, 포지셔닝)
- 차별화 포지셔닝 맵
- "우리만 할 수 있는 것" 리스트

---

### Phase 2: MVP 개발 (Week 9-16)

#### 🎯 활동 4: 온톨로지 설계 워크샵
**참여자**: PM + 데이터 엔지니어 + 리드 개발자 + 1-2명 파워 유저

**활동**:
1. 도메인 모델링: 엔티티, 관계, 속성 정의
2. 사용 시나리오 기반 스키마 검증
3. 유지보수 고려사항 (스키마 진화, 버전 관리)

**산출물**:
- 온톨로지 스키마 v1.0
- 데이터 매핑 문서
- PM용 온톨로지 맵 (Visual Diagram)

---

#### 🎯 활동 5: PoC 빌드 & 측정
**Spike 개발 (2주 타임박스)**:
- 1개 고객 데이터로 병목 진단 파이프라인 구축
- 정확도 기준선 측정 (수동 레이블링 vs AI 출력)

**Learning Goal**:
- 온톨로지가 실제로 필요한가? (vs 단순 휴리스틱)
- LLM이 어디에 필요한가? (추론 vs 분류)

---

#### 🎯 활동 6: 파일럿 프로그램 운영
**구조 (8주)**:
- 5개 고객
- 주간 리포트 발송 + 격주 체크인 콜
- 사용 로그 + 정성적 피드백 수집

**측정**:
- 리포트 열람률, 액션 전환율
- 정확도 피드백 (리크루터 검증)
- NPS, 지불 의향

---

### Phase 3: Iteration & Scale Decision (Week 17-24)

#### 🎯 활동 7: 합성 및 결정
**활동**:
- 모든 가정 테스트 결과 종합
- PRISM 전략 리뷰 (`product-strategy-review.mdc`)
- Go/No-Go 결정 프레임워크 적용

**Decision Gate**:
```
✅ GO (성공 기준 70% 이상)
   → Wave 2 투자, 온톨로지 v2.0 (후보자 엔티티)

⚠️ PIVOT (40-70%)
   → MVP 범위 조정 (위험 시그널 제거, 병목 진단만 집중)
   → 4주 추가 파일럿

❌ STOP (40% 미만)
   → 근본적 재검토
   → 온톨로지 접근 vs Use Case 선정 문제 진단
```

---

#### 🎯 활동 8: 로드맵 커뮤니케이션
**대상**: 경영진, 영업, CS, 엔지니어링

**형식**:
- 1-pager: 비전, 검증 결과, 로드맵, 리소스 요구
- Demo Day: 실제 고객 케이스 시연
- FAQ: 기술 리스크, 경쟁 대응, 가격 전략

---

## 6. 추가 프레임워크 및 도구

### Evidence-Guided 접근
이 전략은 Itamar Gilad의 Evidence-Guided 방법론과 완벽히 맞습니다.

**Evidence 유형**:
1. **시장 신호**: 경쟁사 동향, 고객 요청 티켓
2. **정성적**: 인터뷰 스냅샷, 사용 관찰
3. **정량적**: 파일럿 메트릭, 가격 민감도 데이터
4. **기술 실험**: PoC 정확도, 온톨로지 성능

**Confidence Level 기준**:
- High (70%+): 여러 소스 교차 검증, 정량적 데이터
- Medium (40-70%): 정성적 패턴, 소규모 샘플
- Low (<40%): 가설, 내부 의견

### Assumption Mapping
모든 가정을 명시적으로 추적:
- `/frameworks/continuous-discovery-habits/indentify-and-test-assumptions.mdc` 활용
- 각 가정에 Risk Level, Test Method, Success Threshold 할당
- 2주마다 가정 로그 업데이트

---

## 7. 실행 요약: PM의 첫 30일 체크리스트

### Week 1-2: Foundation
- [ ] 전략 문서 작성 (PRISM 템플릿)
- [ ] 가정 5개 명시화 및 테스트 계획
- [ ] 인터뷰 가이드 작성 (JTBD 기반)
- [ ] 5개 고객 인터뷰 스케줄링

### Week 3-4: Discovery
- [ ] 10개 고객 인터뷰 완료 (snapshots 생성)
- [ ] 데이터 품질 감사 수행
- [ ] 경쟁 분석 완료
- [ ] MVP 범위 확정 (stakeholder 정렬)

### Week 5-6: PoC
- [ ] 온톨로지 워크샵 (스키마 v1.0)
- [ ] 2주 PoC 스파이크 시작
- [ ] 파일럿 고객 5개 확정

### Week 7-8: Validation Setup
- [ ] PoC 결과 평가 (정확도, 복잡도)
- [ ] 파일럿 프로그램 킥오프
- [ ] 측정 대시보드 구축

---

## 8. 최종 조언: 위험 회피 전략

### ⚠️ 가장 큰 리스크: "기술에 빠져 고객을 잃는다"

**방지책**:

1. **고객 접점 유지**
   - 최소 주 2회 고객 대화 (인터뷰, 파일럿 체크인)
   - 엔지니어와의 회의만큼 고객과의 회의에 시간 투자

2. **증분적 가치**
   - 온톨로지 전체 구축 전에 작은 가치를 먼저 증명
   - "6개월 후 완성품"보다 "매달 작은 성과"

3. **설명 가능성 우선**
   - AI 출력에 항상 "왜"를 포함 (신뢰 구축)
   - "AI가 이렇게 추천했어요"보다 "과거 데이터 X, Y, Z를 분석한 결과..."

4. **Exit 전략**
   - 각 Wave마다 명확한 Go/No-Go 기준 설정
   - Sunk Cost Fallacy 피하기 (이미 투자했다고 계속 가는 게 아님)

### 🎯 PM의 핵심 역할

- 엔지니어가 온톨로지 설계에 과몰입할 때 **"고객이 정말 이걸 원하나?"**로 되돌리기
- 비즈니스 가치를 지속적으로 정량화 (ROI 계산기, 사례 연구)
- 조직 내 기대치 관리 (이것은 **12개월 여정**입니다)

---

## 다음 단계

제안하는 다음 액션:
1. **전략 문서 초안 작성** (PRISM 템플릿 기반)
2. **인터뷰 가이드 개발** (10개 질문 + Wizard of Oz 시나리오)
3. **데이터 품질 감사 계획** (엔지니어팀과 협업)

어떤 부분을 더 깊이 탐구하고 싶으신가요?
