# 라운드(Round)의 AI 철학

**작성일**: 2025-12-03
**버전**: v1.0
**관련 제품**: ATS 온톨로지 기반 AI 추천 시스템

---

## 📌 핵심 메시지

> **"채용 담당자를 대체하는 AI가 아닌,**
> **채용 담당자를 더 똑똑하게 만드는 AI"**

라운드는 AI를 채용 담당자의 **똑똑한 비서**로 정의합니다.
AI는 사람의 판단을 대체하지 않고, **강화**합니다.

---

## 🎯 철학의 배경

### 문제 인식: AI에 대한 두 가지 잘못된 접근

많은 채용 AI 제품이 다음과 같이 포지셔닝합니다:
- "AI가 자동으로 최적 후보자를 매칭합니다"
- "AI가 합불을 판단해줍니다"
- "AI가 면접을 대신합니다"

이것은 **AI라는 '도구'가 '목적'이 되는 위험한 시그널**입니다.

### 실제 현장의 목소리

**채용 담당자들의 우려**:
> "AI 때문에 내 자리가 없어지는 것 아니야?"

**실무자(보리)의 경험**:
- HireVue 같은 AI 면접 평가 도구 도입 시
- 경영진: "AI가 면접관 편향을 없애줄 거야!"
- 실무자: "그럼 우리는 뭐해? 면접도 AI가 다 하는 거야?"
- 결과: **엄청난 반발** → "참고용"으로만 사용 → 아무도 안 봄 → **실패**

### 우리의 믿음

**AI는 언제나 정확하지 않고 틀릴 수도 있다는 전제**를 잊지 않고,
고객이 해결하고자 하는 **진짜 문제**를 깊이 파고들다 보면,

결국 채용 AI의 올바른 방향은:
**사람의 판단을 강화시켜주는 똑똑한 비서**가 되어야 합니다.

---

## 🏛️ 3가지 설계 원칙

### 원칙 1: 투명성 (Transparency)

**정의**: AI는 항상 "왜 이 제안을 하는지" 명확한 근거를 제시합니다.

**구현 방법**:
```
❌ 나쁜 예:
"이 후보자는 적합도 75%입니다."
(근거 없음, 블랙박스)

✅ 좋은 예:
"이 후보자는 다음 이유로 주의가 필요합니다:
 1. 6개월 전 동일 포지션 지원 후 레퍼런스 체크 단계에서 중단
 2. 유사 프로필 후보 3명이 입사 6개월 내 퇴사 (퇴사율 100%)
 3. 연봉 요구 ₩9000만 (시장 평균 ₩7500만, +20% Gap)
    → 과거 데이터: Gap +15% 이상 시 오퍼레터율 85%"
```

**제품 적용**:
- 모든 AI 인사이트에 **"근거 보기"** 버튼
- 근거는 **구체적 데이터 포인트** 3-5개
- "알고리즘이 판단했습니다" 같은 모호한 설명 금지

---

### 원칙 2: 오버라이드 가능성 (Override)

**정의**: 최종 판단은 항상 사람이 하며, AI 제안을 무시하거나 수정할 수 있습니다.

**구현 방법**:
```
UI 예시:
┌─────────────────────────────────┐
│ 🚨 AI 위험 시그널 알림           │
│                                 │
│ 후보자: 김OO                     │
│ 발견된 리스크: [3가지]           │
│ 상세 근거: [펼쳐보기]            │
│                                 │
│ ┌─────────────┐ ┌─────────────┐│
│ │ 제안 수락   │ │ 무시하기    ││
│ └─────────────┘ └─────────────┘│
│                                 │
│ [나중에 다시 보기]               │
└─────────────────────────────────┘

중요: "무시하기" 버튼이 "수락" 버튼만큼 크고 눈에 띄어야 함!
```

**제품 적용**:
- 모든 AI 제안에 **명확한 거부 옵션**
- 거부 시 "왜 거부했는지" 간단한 피드백 수집 (선택 사항)
- 거부한 제안도 기록 (학습 루프에 활용)

---

### 원칙 3: 학습 루프 (Learning Loop)

**정의**: AI가 틀릴 수 있음을 인정하고, 사람의 피드백으로 지속적으로 개선합니다.

**구현 방법**:
```
예시: AI가 예측을 틀렸을 때

AI 알림:
"지난주 '후보 A 오퍼레터 확률 80%'로 예측했는데,
 실제로는 수락했습니다. 예측이 틀렸습니다.

 원인 분석:
 - AI는 '연봉 Gap +20%'를 주요 리스크로 판단
 - 실제로는 '업무 내용'을 더 중시했음
 - 이 패턴을 학습하여 다음부터 개선하겠습니다."

→ 이렇게 솔직하면 오히려 신뢰도 UP
```

**제품 적용**:
- Human-in-the-loop 설계
- 사용자가 AI 제안을 수락/거부 → AI 학습 데이터로 활용
- 주기적으로 "AI 정확도 리포트" 공유 (예: 이번 달 병목 진단 정확도 78%)
- 틀린 예측에 대한 회고와 개선 공유

---

## 💡 실제 적용: "자동화" vs "보조" 비교

| 상황 | "자동화" 접근 (경쟁사) | "보조" 접근 (라운드) |
|------|----------------------|---------------------|
| **후보자 추천** | "AI가 최적 후보 3명을 선정했습니다" | "AI가 유사 후보 5명을 비교 분석했습니다. 검토해보세요" |
| **오퍼레터 예측** | "이 후보는 90% 오퍼레터합니다" | "과거 유사 케이스 10건 중 9건이 오퍼레터했습니다. 위험 시그널: [3가지]" |
| **면접 평가** | "AI 점수: 75점" | "면접관 3명의 평가 패턴 분석 결과, 김 부장님이 유독 낮게 평가했습니다 (과거 평균 -15%)" |
| **프로세스 진행** | "다음 단계로 자동 이동되었습니다" | "이 후보는 5일간 연락이 없습니다. 팔로업 이메일 발송을 권장합니다" |

---

## 🎯 메시징 가이드라인

### 제품 메시징 (외부 커뮤니케이션)

**홈페이지 Hero Section**:
```
메인 헤드라인:
"채용 담당자를 대체하는 AI가 아닌,
 채용 담당자를 더 똑똑하게 만드는 AI"

서브 헤드라인:
"라운드는 채용 프로세스의 동적 데이터를 분석하여
 당신이 놓칠 뻔한 인사이트를 알려드립니다"
```

**Feature 설명**:
```
❌ 피할 표현:
- "AI가 자동으로..."
- "AI가 판단합니다"
- "AI가 대신해줍니다"

✅ 권장 표현:
- "AI가 알려드립니다"
- "AI가 발견했습니다"
- "AI가 제안합니다"
- "AI가 분석했습니다"
```

### Sales Deck

**Pain Point 슬라이드**:
```
"채용 담당자는 매일 200개의 태스크를 관리합니다.
 중요한 시그널을 놓치기 쉽습니다."
```

**Solution 슬라이드**:
```
"라운드는 채용 담당자의 일자리를 빼앗지 않습니다.
 대신, 채용 담당자가 매일 8시간이 아니라
 2시간만 일해도 같은 성과를 낼 수 있게 만듭니다."
```

**Objection Handling**:
```
Q: "AI가 실수하면 누가 책임지나요?"
A: "라운드의 AI는 제안만 합니다. 최종 결정은 항상 사람이 하기 때문에,
    책임은 항상 명확합니다. AI는 당신의 판단을 돕는 도구일 뿐입니다."

Q: "채용 담당자가 필요 없어지는 거 아닌가요?"
A: "전혀 그렇지 않습니다. 라운드는 채용 담당자가 더 전략적인 일에
    집중할 수 있도록, 반복적인 데이터 분석과 모니터링을 돕습니다.
    예: 200개 후보 중 '오늘 팔로업 필요한 5명'을 찾는 것."
```

---

## 🏆 전략적 가치

### 1. 시장 차별화 포지셔닝

**경쟁 구도**:
```
경쟁사 (Quadrant 1: 자동화)
├─ HireVue: AI 면접 자동 평가
├─ Pymetrics: AI 적성 검사
└─ Eightfold: AI 자동 매칭

라운드 (Quadrant 2: 증강/Augmentation)
└─ 사람 + AI 협업
   → 투명성, 오버라이드, 학습 루프
```

이 포지셔닝은 경쟁사들이 "자동화"로 후킹할 때,
라운드는 **"신뢰"**로 차별화합니다.

### 2. B2B 구매 결정 프로세스 최적화

**B2B 구매자(HR 리더, CHRO)의 3대 두려움**:
1. "AI가 실수하면 누가 책임지나?" → **오버라이드 가능성**으로 해소
2. "채용 차별 소송 걸리면?" → **투명성**으로 해소 (감사 가능)
3. "HR 팀원들이 반발하면?" → **"일자리 빼앗지 않음"** 메시지로 해소

라운드의 철학은 이 3가지 두려움을 정면으로 해소하여
**구매 장벽을 낮춥니다.**

### 3. 지속 가능한 성장 (Flywheel)

```
사람이 AI 제안을 수용/거부
  ↓
AI가 왜 거부했는지 학습
  ↓
다음 제안이 더 정확해짐
  ↓
신뢰도 증가 → 더 많이 사용
  ↓
더 많은 데이터 → AI 개선
  (반복)
```

"자동화" 접근은 이 루프가 없습니다.
하지만 "보조" 접근은 **Human-in-the-loop**로 지속적으로 개선됩니다.

---

## 📋 제품 개발 체크리스트

새로운 AI 기능을 개발할 때, 다음 질문에 답하세요:

### 투명성 체크
- [ ] AI가 "왜 이 제안을 하는지" 명확한 근거를 보여주는가?
- [ ] 근거는 구체적 데이터 포인트 3-5개를 포함하는가?
- [ ] 사용자가 "근거 보기"를 쉽게 클릭할 수 있는가?

### 오버라이드 체크
- [ ] 사용자가 AI 제안을 거부할 수 있는가?
- [ ] "무시하기" 버튼이 "수락" 버튼만큼 눈에 띄는가?
- [ ] AI 제안을 거부해도 워크플로우가 정상적으로 진행되는가?

### 학습 루프 체크
- [ ] AI가 틀렸을 때를 감지할 수 있는가?
- [ ] 사용자의 수락/거부 피드백을 수집하는가?
- [ ] 이 피드백을 AI 개선에 활용하는 프로세스가 있는가?

### 메시징 체크
- [ ] "AI가 자동으로..." 같은 표현을 피했는가?
- [ ] "AI가 알려드립니다", "제안합니다" 같은 보조 역할 표현을 사용했는가?
- [ ] 사용자가 "내가 최종 판단자"라고 느낄 수 있는가?

---

## 🎓 사례 연구: 보리(HR 실무자)의 경험

### Before (HireVue, 자동화 접근)

**상황**:
- 대기업에서 AI 면접 평가 도구 도입
- AI가 후보자 표정, 목소리를 분석하여 "적합도 점수" 제공

**경영진 기대**:
- "AI가 면접관 편향을 없애줄 것"
- "채용 품질 향상"

**실무자 반응**:
- "AI가 후보의 뭘 알겠어? 표정 분석? 말도 안 돼"
- "그럼 우리는 뭐해? 면접도 AI가 다 하는 거야?"
- **엄청난 반발**

**결과**:
- 참고용으로만 사용 → 아무도 안 봄 → **실패**

### After (라운드 접근이라면?)

**같은 상황에 라운드 방식 적용**:

**AI 제안**:
```
┌─────────────────────────────────────────────┐
│ 후보자: 김OO - Backend Developer            │
│                                             │
│ 💡 AI가 발견한 인사이트 3가지               │
│                                             │
│ 1. 면접 응답 패턴 분석                      │
│    - "팀 협업" 질문 시 구체적 사례 2개 언급 │
│    - "기술 깊이" 질문 시 표면적 답변        │
│    → 과거 유사 패턴: 개인 기여는 강하나    │
│      팀플레이는 약한 후보 (5건 중 3건)     │
│                                             │
│ 2. 경력 일관성                              │
│    - 최근 3년간 회사 3번 이직               │
│    - 평균 재직 기간: 11개월                 │
│    → 당사 유사 케이스: 2년 내 퇴사 확률 70%│
│                                             │
│ 3. 연봉 기대치                              │
│    - 요구: ₩9000만                          │
│    - 시장 평균: ₩7500만 (+20%)             │
│                                             │
│ 💼 제안: 2차 면접 시 다음 질문 고려        │
│    - "가장 오래 근무한 회사는? 왜 퇴사?"   │
│    - "팀 내 갈등 상황 사례 + 해결 방법"    │
│    - "연봉 외 중요하게 여기는 것?"         │
│                                             │
│ ┌──────────┐ ┌──────────┐                 │
│ │ 참고함   │ │ 무시하기 │                 │
│ └──────────┘ └──────────┘                 │
│ [나중에 다시 보기]                          │
└─────────────────────────────────────────────┘
```

**실무자 반응 (예상)**:
- "아, 이런 패턴은 내가 놓쳤을 수도 있네"
- "2차 면접 때 저 질문들 꼭 물어봐야겠다"
- "연봉 협상 전략도 다시 짜야겠어"

**차이점**:
1. AI가 "합격/불합격" 판단 ❌ → 인사이트 제공 ✅
2. 블랙박스 ❌ → 명확한 근거 3가지 ✅
3. "AI가 판단" ❌ → "AI가 제안, 사람이 판단" ✅

---

## 📚 참고 자료 및 영향

### 영향을 받은 사상

**1. Human-AI Collaboration (MIT CSAIL)**
- Iyad Rahwan 교수의 연구
- "AI는 인간을 대체하는 것이 아니라 증강(Augment)해야 한다"

**2. Explainable AI (XAI)**
- DARPA의 XAI 프로그램
- "AI 결정의 투명성이 신뢰의 핵심"

**3. Human-in-the-Loop Machine Learning**
- Robert Monarch의 저서
- "사람의 피드백이 AI를 더 똑똑하게 만든다"

### 업계 실패 사례에서 배운 교훈

**HireVue (2019-2020)**
- AI 면접 평가로 편향 논란
- 2021년 표정 분석 기능 제거
- 교훈: **블랙박스 AI는 신뢰받지 못한다**

**Amazon 채용 AI (2018)**
- 여성 후보자 차별 논란
- 과거 데이터 편향이 AI에 그대로 반영
- 교훈: **AI는 과거 편향을 학습할 수 있다 → 투명성 필수**

**LinkedIn Easy Apply + AI 매칭 (2020)**
- 지원자 폭증으로 채용 담당자 부담 증가
- "AI가 알아서 매칭해줄 줄 알았는데..."
- 교훈: **자동화만으로는 문제 해결 안 됨**

---

## 🔄 버전 히스토리

### v1.0 (2025-12-03)
- 초기 버전 작성
- 제리(PM 전략가), 보리(HR 실무자) 의견 통합
- 3가지 설계 원칙 수립
- 제품 개발 체크리스트 작성

---

## 📞 질문 및 피드백

이 철학에 대한 질문이나 제안이 있으신가요?

**담당 PM**: Terry
**Slack Channel**: #product-philosophy
**마지막 리뷰**: 2025-12-03

---

**이 철학은 라운드의 모든 AI 제품 개발에 적용됩니다.**
